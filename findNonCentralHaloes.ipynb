{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.stats as sp\n",
    "import matplotlib as mpl\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_unique_id(unique_id):\n",
    "    \"\"\"Splits the ids assign to the subhalos by the merger tree code by snap number and subfind number \"\"\"\n",
    "    subfind_number = int(unique_id % 1e6)\n",
    "    snap_number = int((unique_id - subfind_number) / 1e6)\n",
    "    \n",
    "    return snap_number, subfind_number\n",
    "\n",
    "def get_main_branch_unique_ids(subtree, node):\n",
    "    \"\"\"Gets the unique ids of the subhalos belonging to the main branch of the selected subhalo (node)\"\"\"\n",
    "    mpb = [node, ]\n",
    "    i = 0\n",
    "    while True:\n",
    "        succesors = list(subtree.successors(node))\n",
    "        if len(succesors) == 0:\n",
    "            break\n",
    "        node = succesors[0] # select only the first succesor (main branch)\n",
    "        mpb.append(node)\n",
    "        \n",
    "    return mpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeaSnap(z, Zs, snapN):\n",
    "    \"\"\"Return the snapshot number closest to the redshfit z, where Zs and snapN are a list of redshifts and snapshots\"\"\"\n",
    "    ii = np.searchsorted(Zs, z)\n",
    "    if z - Zs[ii-1] < Zs[ii]-z:\n",
    "        return snapN[ii-1]\n",
    "    else:\n",
    "        return snapN[ii]\n",
    "    \n",
    "def getFofId(fofZ0, z, tree, Zs, snapN):\n",
    "    \"\"\"return the snapshot and the fofid of the main progenitor of the fofz0 subgroup at redhsift z\"\"\"\n",
    "    uniqueID0 = int(128*1e6+fofZ0)\n",
    "    stree = networkx.dfs_tree(tree, str(uniqueID0))\n",
    "    mtree = get_main_branch_unique_ids(stree, str(uniqueID0))\n",
    "    snapZ = getNeaSnap(z, Zs, snapN)\n",
    "    numberFoF, nsnapL = [], [] \n",
    "    for m in mtree:\n",
    "        tsnapN, tsfid = split_unique_id(int(m))\n",
    "        numberFoF.append(tsfid)\n",
    "        nsnapL.append(tsnapN)\n",
    "    numberFoF, nsnapL = np.array(numberFoF), np.array(nsnapL)\n",
    "    iid = np.where(nsnapL==snapZ)\n",
    "    if iid[0].size > 0:\n",
    "        iid = iid[0][0]\n",
    "    else:\n",
    "        raise Exception('The subgroup {} has no progenitors at redshift {}'.format(fofZ0, z))\n",
    "    return snapZ, numberFoF[iid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the redhsift/snapnumber lists\n",
    "sim = h5py.File('/data/cielo/simulations/LG1/LG1.hdf5', 'r')\n",
    "\n",
    "Zs, snapN = [], []\n",
    "\n",
    "for i in range(128, 109, -1):\n",
    "    sname = 'SnapNumber_{}/Header/Redshift'.format(i)\n",
    "    zt = sim[sname][()]\n",
    "    Zs.append(zt)\n",
    "    snapN.append(i)\n",
    "\n",
    "Zs, snapN = np.array(Zs), np.array(snapN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now for something completely different\n",
    "# lets find all the halos and a list of subhalos\n",
    "# if any of the offsets of gas particles is negative, i remove the subhalo from the list\n",
    "\n",
    "GrouList = sim['SnapNumber_127/Groups/GroupNumber'][()]\n",
    "SubGroupList = sim['SnapNumber_127/SubGroups/GroupNumber'][()]\n",
    "\n",
    "SubGroupPass, SubGroupPassCentral = [], []\n",
    "subGroupCentral_wS = []\n",
    "subGroupCentral_woS = []\n",
    "\n",
    "for g in GrouList:\n",
    "    ii = np.where(SubGroupList==g)[0]\n",
    "    if ii.size>1: # at least a satellite\n",
    "        HalfMass = sim['SnapNumber_127/SubGroups/SubGroupHalfMass'][ii]\n",
    "        jj = np.argsort(HalfMass) # idk if halfmass\n",
    "        ii2 = ii[jj[:-1]] # all the index but the more massive\n",
    "        iMM = ii[-1] # the most massive one\n",
    "        ii2 = np.sort(ii2) # the index must be sorted for reading from a hdf5, idk why\n",
    "        #OffG = sim['SnapNumber_127/SubGroups/PartType0/Offsets'][ii2]\n",
    "        #jj2 = np.where((OffG[:,0]>=0) & (OffG[:,1]>=0))[0]\n",
    "        #if jj2.size>0:# at least one:\n",
    "        #    ii3 = ii2[jj2]\n",
    "        #    SubGroupPass.extend(list(ii3))\n",
    "        #    SubGroupPassCentral.extend([iMM]*ii3.size)\n",
    "        SubGroupPass.extend(list(ii2)) # this is the version without checking if has particles at z=0\n",
    "        SubGroupPassCentral.extend([iMM]*ii2.size)\n",
    "        \n",
    "        OffMM = sim['SnapNumber_128/SubGroups/PartType0/Offsets'][iMM] # this must be one set of offsets\n",
    "        if OffMM[0]>=0 and OffMM[1]>=0:\n",
    "            subGroupCentral_wS.append(iMM)\n",
    "    elif ii.size==1: # just a central galaxy:\n",
    "        OffOG = sim['SnapNumber_128/SubGroups/PartType0/Offsets'][ii[0]]\n",
    "        if OffOG[0]>=0 and OffOG[1]>=0:\n",
    "            subGroupCentral_woS.append(ii[0])\n",
    "        \n",
    "\n",
    "SubGroupPass, SubGroupPassCentral = np.array(SubGroupPass), np.array(SubGroupPassCentral)\n",
    "subGroupCentral_wS = np.array(subGroupCentral_wS)\n",
    "subGroupCentral_woS = np.array(subGroupCentral_woS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 1012, 10, 454)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroupPass.size, SubGroupPassCentral.size, subGroupCentral_wS.size, subGroupCentral_woS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok,lets find out if any of those had gas particles, or at least a progenitors, at z=2\n",
    "trees = networkx.read_multiline_adjlist('/data/cielo/simulations/LG1/LG1_merger_trees.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubGroupPass2, SubGroupAtZ2 = [], []\n",
    "zT = 0.2\n",
    "\n",
    "for ss in SubGroupPass:\n",
    "    try:\n",
    "        snap, fofid = getFofId(ss, zT, trees, Zs, snapN)\n",
    "        OffG = sim['SnapNumber_{}/SubGroups/PartType0/Offsets'.format(snap)][fofid]\n",
    "        if OffG[0]>=0 and OffG[1]>=0:\n",
    "            SubGroupPass2.append(ss)\n",
    "            SubGroupAtZ2.append(fofid)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "SubGroupPass2, SubGroupAtZ2 = np.array(SubGroupPass2), np.array(SubGroupAtZ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroupPass2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(SubGroupPassCentral).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu = np.unique(SubGroupPassCentral)\n",
    "c =0\n",
    "for u in uu:\n",
    "    Off = sim['SnapNumber_128/SubGroups/PartType0/Offsets'][u]\n",
    "    if Off[0]>=0 and Off[1]>=0:\n",
    "        c +=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm gonna write this down, as hdf5, I guess.\n",
    "with h5py.File('SatelliteList.h5', 'w') as f:\n",
    "    f.create_dataset('SatelliteList', data=SubGroupPass)\n",
    "    f.create_dataset('SatelliteCentral', data=SubGroupPassCentral)\n",
    "    #f.create_dataset('CentralLists/withSatellites', data=subGroupCentral_wS)\n",
    "    #f.create_dataset('CentralLists/withoutSatellites', data=subGroupCentral_woS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now for something completely different\n",
    "# lets find all the halos and a list of subhalos\n",
    "# if any of the offsets of gas particles is negative, i remove the subhalo from the list\n",
    "\n",
    "SubGroupPassV2, SubGroupPassCentralV2 = [], []\n",
    "\n",
    "for g in GrouList:\n",
    "    ii = np.where(SubGroupList==g)[0]\n",
    "    if ii.size>1: # at least a satellite\n",
    "        ii2 = ii[1:] # all the index but the first\n",
    "        iMM = ii[0] # the most massive one\n",
    "        ii2 = np.sort(ii2) # the index must be sorted for reading from a hdf5, idk why\n",
    "        SubGroupPassV2.extend(list(ii2)) # this is the version without checking if has particles at z=0\n",
    "        SubGroupPassCentralV2.extend([iMM]*ii2.size)\n",
    "        \n",
    "SubGroupPassV2, SubGroupPassCentralV2 = np.array(SubGroupPass), np.array(SubGroupPassCentral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 1012)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroupPassV2.size, SubGroupPassCentralV2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroupPassV2-SubGroupPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroupPassCentralV2-SubGroupPassCentral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((SubGroupPassV2==SubGroupPass)==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
