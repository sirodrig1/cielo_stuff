{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snapshots are in HDF5 format. They can easily be read using the [h5py](http://docs.h5py.org/en/stable/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each simulation has a single point of entry file. This file gives access to:\n",
    "\n",
    "- ALL snapshots\n",
    "- ALL header information\n",
    "- ALL FOF and SubFind outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = h5py.File('/disk1/lbignone/data/cielo/simulations/LG1/LG1.hdf5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SnapNumber_100\n",
      "SnapNumber_101\n",
      "SnapNumber_102\n",
      "SnapNumber_103\n",
      "SnapNumber_104\n",
      "SnapNumber_105\n",
      "SnapNumber_106\n",
      "SnapNumber_107\n",
      "SnapNumber_108\n",
      "SnapNumber_109\n",
      "SnapNumber_110\n",
      "SnapNumber_111\n",
      "SnapNumber_112\n",
      "SnapNumber_113\n",
      "SnapNumber_114\n",
      "SnapNumber_115\n",
      "SnapNumber_116\n",
      "SnapNumber_117\n",
      "SnapNumber_118\n",
      "SnapNumber_119\n",
      "SnapNumber_120\n",
      "SnapNumber_121\n",
      "SnapNumber_122\n",
      "SnapNumber_123\n",
      "SnapNumber_124\n",
      "SnapNumber_125\n",
      "SnapNumber_126\n",
      "SnapNumber_127\n",
      "SnapNumber_128\n",
      "SnapNumber_30\n",
      "SnapNumber_31\n",
      "SnapNumber_32\n",
      "SnapNumber_33\n",
      "SnapNumber_34\n",
      "SnapNumber_35\n",
      "SnapNumber_36\n",
      "SnapNumber_37\n",
      "SnapNumber_38\n",
      "SnapNumber_39\n",
      "SnapNumber_40\n",
      "SnapNumber_41\n",
      "SnapNumber_42\n",
      "SnapNumber_43\n",
      "SnapNumber_44\n",
      "SnapNumber_45\n",
      "SnapNumber_46\n",
      "SnapNumber_47\n",
      "SnapNumber_48\n",
      "SnapNumber_49\n",
      "SnapNumber_50\n",
      "SnapNumber_51\n",
      "SnapNumber_52\n",
      "SnapNumber_53\n",
      "SnapNumber_54\n",
      "SnapNumber_55\n",
      "SnapNumber_56\n",
      "SnapNumber_57\n",
      "SnapNumber_58\n",
      "SnapNumber_59\n",
      "SnapNumber_60\n",
      "SnapNumber_61\n",
      "SnapNumber_62\n",
      "SnapNumber_63\n",
      "SnapNumber_64\n",
      "SnapNumber_65\n",
      "SnapNumber_66\n",
      "SnapNumber_67\n",
      "SnapNumber_68\n",
      "SnapNumber_69\n",
      "SnapNumber_70\n",
      "SnapNumber_71\n",
      "SnapNumber_72\n",
      "SnapNumber_73\n",
      "SnapNumber_74\n",
      "SnapNumber_75\n",
      "SnapNumber_76\n",
      "SnapNumber_77\n",
      "SnapNumber_78\n",
      "SnapNumber_79\n",
      "SnapNumber_80\n",
      "SnapNumber_81\n",
      "SnapNumber_82\n",
      "SnapNumber_83\n",
      "SnapNumber_84\n",
      "SnapNumber_85\n",
      "SnapNumber_86\n",
      "SnapNumber_87\n",
      "SnapNumber_88\n",
      "SnapNumber_89\n",
      "SnapNumber_90\n",
      "SnapNumber_91\n",
      "SnapNumber_92\n",
      "SnapNumber_93\n",
      "SnapNumber_94\n",
      "SnapNumber_95\n",
      "SnapNumber_96\n",
      "SnapNumber_97\n",
      "SnapNumber_98\n",
      "SnapNumber_99\n"
     ]
    }
   ],
   "source": [
    "# Exploring the keys() contained in simulation we can see that there is a single entry for each snapshot (redshift)\n",
    "\n",
    "for key in simulation.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access a snapshot simply select one\n",
    "\n",
    "snapshot = simulation['SnapNumber_127']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups\n",
      "Header\n",
      "PartType0\n",
      "PartType1\n",
      "PartType4\n",
      "PartType5\n",
      "SubGroups\n"
     ]
    }
   ],
   "source": [
    "# We can now explore what information each snapshot contains\n",
    "\n",
    "for key in snapshot.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information stored in the snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the header datagroup contains basic information about the snapshot, such as redshift, cosmological parameters and the MassTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxSize\n",
      "HubbleParam\n",
      "MassTable\n",
      "Omega0\n",
      "OmegaLambda\n",
      "Redshift\n",
      "Time\n"
     ]
    }
   ],
   "source": [
    "Header = snapshot['Header']\n",
    "\n",
    "for key in Header.keys():\n",
    "    print(f'{key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a description of each dataset can be viewed by accesing the .attrs property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxSize:\n",
      "\tSpatial extent of the periodic box (in co-moving units)\n",
      "HubbleParam:\n",
      "\tHubble parameter\n",
      "MassTable:\n",
      "\tThe mass of each particle type. If set to 0 for a type which is present, individual particlemasses can found in the Masses dataset instead\n",
      "Omega0:\n",
      "\tThe cosmological density parameter for matter\n",
      "OmegaLambda:\n",
      "\t The cosmological density parameter for the cosmological constant\n",
      "Redshift:\n",
      "\tThe redshift corresponding to the current snapshot\n",
      "Time:\n",
      "\tThe scale factor a (=1/(1+z)) corresponding to the current snapshot\n"
     ]
    }
   ],
   "source": [
    "for key in Header.keys():\n",
    "    dataset = Header[f'{key}']\n",
    "    description = dataset.attrs['description']\n",
    "    \n",
    "    print(f'{key}:\\n\\t{description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxSize:\t100000.0\n",
      "HubbleParam:\t0.6711\n",
      "MassTable:\t[0.         0.00010843 0.         0.         0.         0.        ]\n",
      "Omega0:\t0.3175\n",
      "OmegaLambda:\t0.6825\n",
      "Redshift:\t2.220446049250313e-16\n",
      "Time:\t0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "for key in Header.keys():\n",
    "    dataset = Header[f'{key}']\n",
    "    \n",
    "    print(f'{key}:\\t{dataset[()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particle level information can be access through the PartType0, PartType1, PartType2, PartType3, PartType4 and PartType5 datagroups\n",
    "\n",
    "The particle numbers correspond to:\n",
    "\n",
    "|# | type|\n",
    "|--|------------------------------|\n",
    "|0 | high-resolution gas|\n",
    "|1 | high-resolution dark matter|\n",
    "|2 | intermediate-resolution dark matter|\n",
    "|3 | intermediate-resolution dark matter|\n",
    "|4 | stars|\n",
    "|5 | low-resolution dark matter|\n",
    "\n",
    "The information actually contained depends on each type. But again, descriptions are available using the .attrs property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abundances:\n",
      "\tMass in individual elements: He, C, Mg, O, Fe, Si, H, N, Ne, S, Ca, Zi (in this order)\n",
      "BindingEnergy:\n",
      "\tParticle binding energy\n",
      "Circularity:\n",
      "\tThe particle circularity calculated as $J_z/J(E)$, where J(E) is the maximum angular momentum of the particles at positions between 50 before and 50 after the particle in question in a list where the stellar particles are sorted by their binding energy\n",
      "Coordinates:\n",
      "\tSpatial position within the periodic box. Co-moving coordinate\n",
      "GroupNumber:\n",
      "\tFoF id of the Group this object belongs to. -1 if the object does not belong to any group\n",
      "Masses:\n",
      "\tMass of this particle\n",
      "ParticleIDs:\n",
      "\tThe unique particle ID\n",
      "Potential:\n",
      "\tGravitational potential energy\n",
      "SpecificAngularMomentum:\n",
      "\t\n",
      "StellarFormationTime:\n",
      "\tThe time (given as the scale factor) when this star was formed\n",
      "SubFindNumber:\n",
      "\tSubFind id of the object this particle belongs to. -1 if the object does not belong to any SubGroup\n",
      "SubGroupNumber:\n",
      "\tSubGroup number this object belongs to. 0 for centrals. -1 if the object does not belongto any SubGroup\n",
      "Velocities:\n",
      "\tSpatial velocity. Multiply this value by $\\sqrt(a)$ to obtain peculiar velocity\n"
     ]
    }
   ],
   "source": [
    "# For example for stars\n",
    "\n",
    "PartType4 = snapshot['PartType4']\n",
    "\n",
    "for key in PartType4.keys():\n",
    "    dataset = PartType4[f'{key}']\n",
    "    description = dataset.attrs['description']\n",
    "    \n",
    "    print(f'{key}:\\n\\t{description}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FoF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the FOF code, which describe the halos can be found under the Groups datagroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupCM:\n",
      "\tCenter of mass of the Group\n",
      "GroupLen:\n",
      "\tTotal number of particles in the group\n",
      "GroupLenType:\n",
      "\tTotal number of particles in the group, split by particle type\n",
      "GroupMassType:\n",
      "\tTotal mass of particles in the group, split by particle type\n",
      "GroupNsubs:\n",
      "\tNumber of SubGroups in each Group\n",
      "GroupNumber:\n",
      "\tFoF id of the Group this object belongs to. -1 if the object does not belong to any group\n",
      "GroupSFR:\n",
      "\t Sum of the individual star formation rates of all gas cells in this group\n",
      "Group_M_Crit200:\n",
      "\tTotal Mass of this group enclosed in a sphere whose mean density is 200 times the critical density of the Universe, at the time the halo is considered\n",
      "Group_M_Mean200:\n",
      "\tTotal Mass of this group enclosed in a sphere whose mean density is 200 times the mean density of the Universe, at the time the halo is considered\n",
      "Group_M_TopHat200:\n",
      "\t\n",
      "Group_R_Crit200:\n",
      "\tComoving Radius of a sphere centered at this Group whose mean density is 200 times the critical density of the Universe, at the time the halo is considered\n",
      "Group_R_Mean200:\n",
      "\tComoving Radius of a sphere centered at this Group whose mean density is 200 times the mean density of the Universe, at the time the halo is considered\n",
      "Group_R_TopHat200:\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "Groups = snapshot['Groups']\n",
    "\n",
    "for key in Groups.keys():\n",
    "    dataset = Groups[f'{key}']\n",
    "    try:\n",
    "        description = dataset.attrs['description']\n",
    "        print(f'{key}:\\n\\t{description}')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SubFind data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly for the subfind data, which can be found under SubGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupNumber:\n",
      "\tFoF id of the Group this object belongs to. -1 if the object does not belong to any group\n",
      "OpticalRadius:\n",
      "\tOptical radii computed as the radius that encompass 83% of stellar and star-forming gas mass belonging to the SubGroup\n",
      "SubFindNumber:\n",
      "\tSubFind id of the object this particle belongs to. -1 if the object does not belong to any SubGroup\n",
      "SubGroupHalfMass:\n",
      "\tHalf mass of the SubGroup\n",
      "SubGroupLen:\n",
      "\tNumber of particles contained in this SubGroup\n",
      "SubGroupMostBoundID:\n",
      "\tParticleID of the most bound particle\n",
      "SubGroupNumber:\n",
      "\tSubGroup number this object belongs to. 0 for centrals. -1 if the object does not belongto any SubGroup\n",
      "SubGroupPos:\n",
      "\tPosition of the most bound particle\n",
      "SubGroupVel:\n",
      "\tPeculiar velocity of the center of mass of the SubGroup\n"
     ]
    }
   ],
   "source": [
    "SubGroups = snapshot['SubGroups']\n",
    "\n",
    "for key in SubGroups.keys():\n",
    "    dataset = SubGroups[f'{key}']\n",
    "    try:\n",
    "        description = dataset.attrs['description']\n",
    "        print(f'{key}:\\n\\t{description}')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offsets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Groups and SubGroups contain also information on the offset location of particles belonging to each particular halo or subhalo. This can be useful to limit the amount of data to load into memory\n",
    "\n",
    "The offsets can be access using the key `PartType[N]/Offset`, where [N] is the particle number.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Offsets\": shape (6027, 2), type \"<f8\">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SubGroups['PartType0/Offsets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details on using the offsets and reading only particlar halos/subhalos are given in a separate notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only explored the contents of the file, to actually use the data we need to load the contents to memory. To do so there are several ways, see (http://docs.h5py.org/en/stable/high/dataset.html#reading-writing-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Coordinates\": shape (17229508, 3), type \"<f4\">"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that \n",
    "\n",
    "Coordinates = PartType4['Coordinates']\n",
    "\n",
    "# Does not acutually load anaything, it acts simply as a placeholder\n",
    "\n",
    "Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52939.516, 50580.35 , 42499.445],\n",
       "       [52939.008, 50572.133, 42509.156],\n",
       "       [52901.645, 50714.305, 42592.742],\n",
       "       ...,\n",
       "       [54639.01 , 51438.266, 45639.094],\n",
       "       [54636.973, 51436.395, 45639.297],\n",
       "       [54634.035, 51434.24 , 45645.77 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oly when we provide indexes or slices the data is read\n",
    "\n",
    "Coordinates = PartType4['Coordinates'][:]\n",
    "\n",
    "Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command reads all the Coordinates into memory, to limit the amount of information to load consult the other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Units and other useful information to convert the snapshot units to physical units can be access also using the .attrs propery\n",
    "\n",
    "These fields rougly follow the EAGLE convention as described in https://arxiv.org/abs/1706.09899. See section 2.3.8 for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['a_exp', 'cgs_conversion_factor', 'cgs_units', 'description', 'description_units', 'h_exp']>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartType4['Coordinates'].attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
